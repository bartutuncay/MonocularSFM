{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa3aefb",
   "metadata": {},
   "source": [
    "# Registration Pipeline\n",
    "\n",
    "### The point cloud registration pipeline takes the following inputs:\n",
    "- Point cloud: outputs of depth estimation pipeline, *any format compatible with Open3D,* **more robust results with colors and normals; also uniform scaling if applicable**\n",
    "\n",
    "### Process:\n",
    "\n",
    "$\\rightarrow$ *Point clouds are downsampled and points are randomly selected using Latin Hypercube Sampling*\n",
    "\n",
    "$\\rightarrow$\n",
    "\n",
    "### Tunable parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d9879",
   "metadata": {},
   "source": [
    "The following should be imported for the registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01134f20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy.stats import qmc\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def procrustes(X, Y):\n",
    "    \"\"\"\n",
    "    Compute the optimal rotation R and translation t that aligns X to Y.\n",
    "    X, Y: (N, 3) arrays of corresponding points.\n",
    "    Returns R (3x3), t (3,).\n",
    "    \"\"\"\n",
    "    # Compute centroids\n",
    "    centroid_X = X.mean(axis=0)\n",
    "    centroid_Y = Y.mean(axis=0)\n",
    "    # Center the points\n",
    "    X_centered = X - centroid_X\n",
    "    Y_centered = Y - centroid_Y\n",
    "    # Cross-covariance matrix\n",
    "    H = X_centered.T @ Y_centered\n",
    "    # SVD\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    # Compute rotation\n",
    "    R = Vt.T @ U.T\n",
    "    # Ensure a proper rotation (determinant = +1)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "    # Compute translation\n",
    "    t = centroid_Y - centroid_X @ R.T\n",
    "    return R, t\n",
    "\n",
    "def sinkhorn(a, b, C, reg, numItermax=1000, tol=1e-9):\n",
    "    \"\"\"\n",
    "    Compute the entropic regularized OT plan using Sinkhorn iterations.\n",
    "    a, b: weight vectors (summing to 1) for source and target.\n",
    "    C: cost matrix (n x m)\n",
    "    reg: regularization strength (epsilon)\n",
    "    \"\"\"\n",
    "    K = np.exp(-C / reg)\n",
    "    u = np.ones_like(a)\n",
    "    v = np.ones_like(b)\n",
    "    for _ in range(numItermax):\n",
    "        u_prev = u.copy()\n",
    "        u = a / (K.dot(v))\n",
    "        v = b / (K.T.dot(u))\n",
    "        if np.linalg.norm(u - u_prev, 1) < tol:\n",
    "            break\n",
    "    return np.diag(u) @ K @ np.diag(v)\n",
    "\n",
    "def register_point_clouds(X, Y):\n",
    "    \"\"\"\n",
    "    Registers point cloud X to Y using the assignment-based OT (Hungarian algorithm)\n",
    "    and Procrustes analysis.\n",
    "    X: (N, 3), Y: (M, 3)\n",
    "    Returns:\n",
    "      - X_reg: (N, 3) aligned version of X\n",
    "      - R: (3, 3) rotation matrix\n",
    "      - t: (3,) translation vector\n",
    "    \"\"\"\n",
    "    # Compute cost matrix (squared Euclidean distances)\n",
    "    C = cdist(X, Y, 'sqeuclidean')\n",
    "    # Solve assignment problem\n",
    "    row_ind, col_ind = linear_sum_assignment(C)\n",
    "    # Matched target points\n",
    "    Y_matched = Y[col_ind]\n",
    "    # Compute best-fit transform\n",
    "    R, t = procrustes(X[row_ind], Y_matched)\n",
    "    # Apply transform to all of X\n",
    "    return R, t\n",
    "\n",
    "def register_sinkhorn(X, Y, reg=0.1):\n",
    "    \"\"\"\n",
    "    Register point cloud X to Y using entropic OT + Procrustes.\n",
    "    Returns aligned X, rotation R, translation t, and transport plan pi.\n",
    "    \"\"\"\n",
    "    n, m = X.shape[0], Y.shape[0]\n",
    "    a = np.ones(n) / n\n",
    "    b = np.ones(m) / m\n",
    "    C = cdist(X, Y, 'sqeuclidean')\n",
    "    pi = sinkhorn(a, b, C, reg)\n",
    "    # Barycentric projection\n",
    "    Y_bar = pi.dot(Y) / pi.sum(axis=1, keepdims=True)\n",
    "    R, t = procrustes(X, Y_bar)\n",
    "    return R, t\n",
    "\n",
    "def compute_similarity_transform(source, target):\n",
    "\t\"\"\"\n",
    "\tComputes scale s, rotation R, and translation t such that:\n",
    "\ttarget ≈ s * R @ source + t\n",
    "\t\"\"\"\n",
    "\t# Center the points\n",
    "\tsrc_centroid = np.mean(source, axis=0)\n",
    "\ttgt_centroid = np.mean(target, axis=0)\n",
    "\tsrc_centered = source - src_centroid\n",
    "\ttgt_centered = target - tgt_centroid\n",
    "\t# Compute scale factor\n",
    "\tsrc_var = np.sum(np.square(src_centered))\n",
    "\ttgt_var = np.sum(np.square(tgt_centered))\n",
    "\tscale = np.sqrt(tgt_var / src_var) if src_var > 0 else 1.0\n",
    "\t# Compute optimal rotation using SVD\n",
    "\tH = src_centered.T @ tgt_centered\n",
    "\tU, _, Vt = np.linalg.svd(H)\n",
    "\tR = Vt.T @ U.T\n",
    "\t# Ensure a proper rotation matrix\n",
    "\tif np.linalg.det(R) < 0:\n",
    "\t\tVt[-1, :] *= -1\n",
    "\t\tR = Vt.T @ U.T\n",
    "\t# Compute translation\n",
    "\tt = tgt_centroid - scale * (R @ src_centroid)\n",
    "\treturn scale, R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b885d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pointclouds = os.listdir('IGP_filtered')\n",
    "pointclouds.sort()\n",
    "voxel_size = 1e-6\n",
    "LHS_count = 10000\n",
    "radius = voxel_size*5 #neighbourhood radius\n",
    "s_tol = 0.01 #similarity tolerance\n",
    "min_cutoff = 1e-5 #minimum distance to camera\n",
    "pcd2 = o3d.io.read_point_cloud(os.path.join('IGP_filtered',pointclouds[0]))\n",
    "pcd2 = pcd2.voxel_down_sample(voxel_size)\n",
    "R_c = np.eye(3)\n",
    "original_normals = []\n",
    "\n",
    "i = 0\n",
    "for path in pointclouds:\n",
    "\tprint('processing pointcloud: ',path)\n",
    "\tpath = os.path.join('IGP_filtered',path)\n",
    "\tsampler = qmc.LatinHypercube(3)\n",
    "\tstart = time.time()\n",
    "\n",
    "\tpoints2 = np.asarray(pcd2.points)\n",
    "\tgnd_level = points2[:,2].min()\n",
    "\n",
    "\tpcd1 = o3d.io.read_point_cloud(path)\n",
    "\tpcd1 = pcd1.voxel_down_sample(voxel_size)\n",
    "\tpoints1 = np.asarray(pcd1.points)\n",
    "\tpoints1[:,2] = points1[:,2]-(points1[:,2].min()-gnd_level)\n",
    "\tmin_bounds = points1.min(axis=0)\n",
    "\tmax_bounds = points1.max(axis=0)\n",
    "\t#print(min_bounds,max_bounds)\n",
    "\tlhs_samples1 = sampler.random(LHS_count)\n",
    "\tsamples_scaled1 = min_bounds + lhs_samples1 * (max_bounds - min_bounds)\n",
    "\n",
    "\t# adaptive search box\n",
    "\tmin_bounds = points2.min(axis=0) if i == 0 else newmin_bounds\n",
    "\tmax_bounds = points2.max(axis=0) if i == 0 else newmax_bounds\n",
    "\t#print(min_bounds,max_bounds)\n",
    "\t#TODO: truncate points close to camera (more likely to be distorted)\n",
    "\n",
    "\tlhs_samples2 = sampler.random(LHS_count)\n",
    "\tsamples_scaled2 = min_bounds + lhs_samples2 * (max_bounds - min_bounds)\n",
    "\t\n",
    "\t\n",
    "\ttree = cKDTree(points1)\n",
    "\t_, idx1 = tree.query(samples_scaled1, k=1)\n",
    "\tsampled_points = points1[idx1]\n",
    "\tcolors = np.asarray(pcd1.colors)\n",
    "\tcolors = np.arctan2(np.sqrt(3) * (colors[:, 1] - colors[:, 2]), 2 * colors[:, 0] - colors[:, 1] - colors[:, 2])\n",
    "\tsampled_colors = colors[idx1]\n",
    "\n",
    "\ttree2 = cKDTree(points2)\n",
    "\t_, idx2 = tree2.query(samples_scaled2, k=1)\n",
    "\tsampled_points2 = points2[idx2]\n",
    "\tcolors2 = np.asarray(pcd2.colors)\n",
    "\tcolors2 = np.arctan2(np.sqrt(3) * (colors2[:, 1] - colors2[:, 2]), 2 * colors2[:, 0] - colors2[:, 1] - colors2[:, 2])\n",
    "\tsampled_colors2 = colors2[idx2]\n",
    "\n",
    "\tnormals = []\n",
    "\tnormals2 = []\n",
    "\tdensities = []\n",
    "\tdensities2 = []\n",
    "\tfor p in sampled_points:\n",
    "\t\tidxs = tree.query_ball_point(p, r=radius)\n",
    "\t\tneighbors = points1[idxs]\n",
    "\t\tdensities.append(len(neighbors))\n",
    "\t\tif len(neighbors) >= 3: # Compute normal via PCA\n",
    "\t\t\tneighbors_centered = neighbors - neighbors.mean(axis=0)\n",
    "\t\t\tcov = neighbors_centered.T @ neighbors_centered\n",
    "\t\t\teigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\t\t\tnormal = eigvecs[:, 0]  # smallest eigenvector → normal\n",
    "\t\telse:\n",
    "\t\t\tnormal = np.array([0, 0, 0])  # or np.nan\n",
    "\t\tnormals.append(normal)\n",
    "\n",
    "\tfor p in sampled_points2:\n",
    "\t\tidxs = tree2.query_ball_point(p, r=radius)\n",
    "\t\tneighbors = points2[idxs]\n",
    "\t\tdensities2.append(len(neighbors))\n",
    "\t\tif len(neighbors) >= 3:\n",
    "\t\t\tneighbors_centered = neighbors - neighbors.mean(axis=0)\n",
    "\t\t\tcov = neighbors_centered.T @ neighbors_centered\n",
    "\t\t\teigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\t\t\tnormal = eigvecs[:, 0]  # smallest eigenvector → normal\n",
    "\t\telse:\n",
    "\t\t\tnormal = np.array([0, 0, 0])  # or np.nan\n",
    "\t\tnormals2.append(normal)\n",
    "\t\n",
    "\t#normals = normals @ R_c.T\n",
    "\n",
    "\tsampled_points = np.asarray(sampled_points).reshape(-1, 3)\n",
    "\tnormals = np.asarray(normals).reshape(-1, 3)\n",
    "\n",
    "\tsampled_points2 = np.asarray(sampled_points2).reshape(-1, 3)\n",
    "\tnormals2 = np.asarray(normals2).reshape(-1, 3)\n",
    "\n",
    "\tdensities = np.asarray(densities).reshape(-1, 1)\n",
    "\t#rank-based density\n",
    "\t#densities = np.argsort(np.argsort(densities),axis=0)\n",
    "\t#densities = densities / (len(densities) - 1)\n",
    "\tsampled_colors = np.asarray(sampled_colors).reshape(-1, 1)*100\n",
    "\t\n",
    "\tdensities2 = np.asarray(densities2).reshape(-1, 1)\n",
    "\t#densities2 = np.argsort(np.argsort(densities2),axis=0)\n",
    "\t#densities2 = densities2 / (len(densities2) - 1)\n",
    "\tsampled_colors2 = np.asarray(sampled_colors2).reshape(-1, 1)*100\n",
    "\n",
    "\n",
    "\t# Concatenate everything: [x, y, z, nx, ny, nz, density, r, g, b]\n",
    "\tcombined1 = np.hstack([sampled_points, normals, sampled_colors])\n",
    "\tcombined2 = np.hstack([sampled_points2, normals2, sampled_colors2])\n",
    "\n",
    "\tarr_view = combined1.view([('', combined1.dtype)] * combined1.shape[1])\n",
    "\tunique_rows, counts = np.unique(arr_view, return_counts=True)\n",
    "\tunique_only = unique_rows[counts == 1]\n",
    "\tcombined1 = unique_only.view(combined1.dtype).reshape(-1, combined1.shape[1])\n",
    "\n",
    "\tarr_view = combined2.view([('', combined2.dtype)] * combined2.shape[1])\n",
    "\tunique_rows, counts = np.unique(arr_view, return_counts=True)\n",
    "\tunique_only = unique_rows[counts == 1]\n",
    "\tcombined2 = unique_only.view(combined2.dtype).reshape(-1, combined2.shape[1])\n",
    "\n",
    "\t# Map similar points based on normals, hue\n",
    "\tmatches = []\n",
    "\tfor p in combined1:\n",
    "\t\tp2 = p\n",
    "\t\tp = p[2:]\n",
    "\t\tc_temp = combined2[:,2:]-p\n",
    "\t\tif len(c_temp > 0):\n",
    "\t\t\tc_temp = np.sqrt(np.sum(c_temp**2,axis=1))\n",
    "\t\t\tms = np.min(c_temp[c_temp>0])\n",
    "\t\t\tidx = np.where(c_temp == ms)[0][0]\n",
    "\t\t\tif ms < s_tol:\n",
    "\t\t\t\tmapped = np.hstack((p2,combined2[idx]))\n",
    "\t\t\t\tmatches.append(mapped)\n",
    "\t\t\t#TODO: update coordinate system after each transform --> rotate normals to match new point cloud (or make register of original normals)\n",
    "\t\t\tcombined2 = np.delete(combined2,idx,axis=0)\n",
    "\tmatches = np.array(matches)\n",
    "\tprint(len(matches))\n",
    "\n",
    "\t##Calculate transform\n",
    "\n",
    "\ts = 1\n",
    "\t#R, t = register_point_clouds(matches[:,0:3], matches[:,7:10]) #optimal transport\n",
    "\n",
    "\tR,t = register_sinkhorn(matches[:,0:3], matches[:,7:10], reg=1.8) #entropic optimal transport\n",
    "\t#TODO: match camera level for all instances\n",
    "\n",
    "\t#s, R, t = compute_similarity_transform(matches[:,0:3], matches[:,7:10])\n",
    "\n",
    "\t#R_c = R@R_c #cumulative rotation\n",
    "\ttransformed_points = s * (points1 @ R.T) + t\n",
    "\tpcd1.points = o3d.utility.Vector3dVector(transformed_points)\n",
    "\t#pcd1c = pcd1.paint_uniform_color([1,0,0])\n",
    "\t#pcd2c = pcd2.paint_uniform_color([0,1,0])\n",
    "\tpcd3 = o3d.geometry.PointCloud() #target\n",
    "\tpcd3.points = o3d.utility.Vector3dVector(matches[:,0:3])\n",
    "\tpcd3 = pcd3.paint_uniform_color([0,1,0])\n",
    "\tpcd4_points = s * (matches[:,7:10] @ R.T) + t\n",
    "\tpcd4 = o3d.geometry.PointCloud() #source, moved\n",
    "\tpcd4.points = o3d.utility.Vector3dVector(pcd4_points)\n",
    "\tpcd4 = pcd4.paint_uniform_color([1,1,0])\n",
    "\tpcd5 = o3d.geometry.PointCloud() #source\n",
    "\tpcd5.points = o3d.utility.Vector3dVector(matches[:,7:10])\n",
    "\tpcd5 = pcd5.paint_uniform_color([1,0,0])\n",
    "\n",
    "\t# update search bounds (pcd1 moves)\n",
    "\tnewmin_bounds = transformed_points.min(axis=0)\n",
    "\tnewmax_bounds = transformed_points.max(axis=0)\n",
    "\n",
    "\tmerged = pcd1 + pcd2\n",
    "\tmerged.remove_statistical_outlier(nb_neighbors=10,std_ratio=0.1)\n",
    "\tpcd2 = merged\n",
    "\tend = time.time()\n",
    "\tprint('processing time:',end-start,'seconds')\n",
    "\ti+=1\n",
    "\tif i > 15:\n",
    "\t\tbreak\n",
    "\n",
    "o3d.visualization.draw_geometries([merged,pcd3,pcd4,pcd5])\n",
    "\n",
    "## workflow\n",
    "# get points with LHS\n",
    "# match based on density, normals (max.neighbors) and color\n",
    "# minimize KL divergence of similar points based on location\n",
    "# adaptive sample count based on point cloud dimensions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
